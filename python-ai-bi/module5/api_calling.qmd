---
title: "大模型API调用"
---

# 大模型API调用

大语言模型(LLM)通过API的形式提供服务，使开发者能够将AI能力集成到各种应用中。本章将介绍如何调用主流大模型API，重点关注OpenAI的GPT系列API，并提供实用的代码示例和最佳实践。

## 大模型API服务概述

目前市场上主要的大模型API服务提供商包括：

:::{.important}
1. **OpenAI**：提供GPT-3.5、GPT-4等模型，是目前应用最广泛的大模型API
2. **Anthropic**：提供Claude系列模型，以安全性和无害性见长
3. **Google AI**：提供PaLM API、Gemini系列API等
4. **Cohere**：提供专注于文本生成、嵌入和文本理解的API
5. **Hugging Face**：提供对多种开源模型的托管API服务
6. **百度文心**：提供文心一言API
7. **讯飞星火**：提供星火认知大模型API
:::

## OpenAI API基础

### API密钥与设置

使用OpenAI API前，需要先注册账号并获取API密钥：

```python
import openai

# 设置API密钥
openai.api_key = "your-api-key-here"  # 替换为你的实际API密钥

# 可选：设置自定义的base URL（如使用Azure OpenAI Service）
# openai.api_base = "https://your-resource-name.openai.azure.com"
```

### API参数详解

OpenAI API的主要参数包括：

1. **模型(model)**：指定使用的模型，如"gpt-4"或"gpt-3.5-turbo"
2. **消息(messages)**：对话历史和当前提问
3. **温度(temperature)**：控制随机性，值越高输出越多样化
4. **最大标记数(max_tokens)**：限制生成文本的长度
5. **Top P(top_p)**：控制生成文本的多样性的另一种方式
6. **频率惩罚(frequency_penalty)**：减少重复词汇的出现
7. **存在惩罚(presence_penalty)**：鼓励模型谈论新话题

### 基础聊天完成请求

```python
from openai import OpenAI

# 初始化OpenAI客户端
client = OpenAI(api_key="your-api-key-here")

# 发送聊天完成请求
response = client.chat.completions.create(
    model="gpt-3.5-turbo",  # 或 "gpt-4" 等
    messages=[
        {"role": "system", "content": "你是一位资深的金融分析师。"},
        {"role": "user", "content": "请分析当前利率上升对房地产市场的影响。"}
    ],
    temperature=0.7,
    max_tokens=500
)

# 输出模型的回复
print(response.choices[0].message.content)
```

### 流式响应

对于长回答，可以使用流式响应逐步获取内容：

```python
response_stream = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "你是一位资深的金融分析师。"},
        {"role": "user", "content": "请分析当前利率上升对房地产市场的影响。"}
    ],
    temperature=0.7,
    max_tokens=500,
    stream=True  # 启用流式响应
)

# 处理流式响应
for chunk in response_stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

## 多轮对话管理

大模型API支持多轮对话，需要管理对话历史：

```python
# 初始化对话历史
conversation_history = [
    {"role": "system", "content": "你是一位助手，帮助用户解答Python编程问题。"}
]

def chat_with_gpt(user_input):
    # 将用户输入添加到对话历史
    conversation_history.append({"role": "user", "content": user_input})
    
    # 发送请求
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=conversation_history,
        temperature=0.7,
        max_tokens=500
    )
    
    # 将助手回复添加到对话历史
    assistant_response = response.choices[0].message.content
    conversation_history.append({"role": "assistant", "content": assistant_response})
    
    return assistant_response

# 使用示例
print(chat_with_gpt("如何在Python中读取CSV文件？"))
print(chat_with_gpt("我想对读取的数据进行分组统计，应该怎么做？"))
```

## 处理API错误

调用API时可能遇到各种错误，需要妥善处理：

```python
import time
import backoff  # pip install backoff

# 使用backoff装饰器自动重试
@backoff.on_exception(backoff.expo, 
                     (openai.RateLimitError, openai.APIConnectionError),
                     max_tries=5)
def make_api_call(messages):
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.7
        )
        return response.choices[0].message.content
    except openai.RateLimitError:
        print("Rate limit exceeded, waiting before retry...")
        time.sleep(20)  # 等待一段时间后重试
        raise  # 重新抛出异常，让backoff处理
    except openai.APIConnectionError:
        print("Connection error, will retry...")
        raise
    except openai.APIError as e:
        print(f"OpenAI API error: {e}")
        return "API错误，请稍后再试。"
    except Exception as e:
        print(f"Unexpected error: {e}")
        return "发生错误，请稍后再试。"
```

## 高级使用技巧

### 函数调用(Function Calling)

GPT-4等模型支持函数调用，可以结构化地调用外部工具：

```python
import json
from datetime import datetime

# 定义函数
def get_current_weather(location, unit="celsius"):
    """获取当前天气"""
    # 这里应该是实际的天气API调用，这只是示例
    weather_info = {
        "北京": {"temperature": 20, "condition": "晴朗"},
        "上海": {"temperature": 25, "condition": "多云"},
        "广州": {"temperature": 30, "condition": "潮湿"}
    }
    return weather_info.get(location, {"temperature": 0, "condition": "未知"})

# 定义可用函数
functions = [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "获取给定位置的当前天气",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "城市名称，如北京、上海",
                    },
                    "unit": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "description": "温度单位",
                    },
                },
                "required": ["location"],
            },
        }
    }
]

# 调用模型并处理函数调用
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "你是一位助手，可以提供天气信息。"},
        {"role": "user", "content": "北京今天天气怎么样？"}
    ],
    tools=functions,
    tool_choice="auto"
)

message = response.choices[0].message

# 检查是否有函数调用
if message.tool_calls:
    for tool_call in message.tool_calls:
        if tool_call.function.name == "get_current_weather":
            # 解析参数
            function_args = json.loads(tool_call.function.arguments)
            
            # 执行函数
            function_response = get_current_weather(
                location=function_args.get("location"),
                unit=function_args.get("unit", "celsius")
            )
            
            # 将函数响应传回模型
            second_response = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "你是一位助手，可以提供天气信息。"},
                    {"role": "user", "content": "北京今天天气怎么样？"},
                    message,
                    {
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "name": "get_current_weather",
                        "content": json.dumps(function_response)
                    }
                ]
            )
            
            print(second_response.choices[0].message.content)
else:
    print(message.content)
```

### 嵌入(Embeddings)向量

嵌入是文本在高维向量空间中的表示，常用于语义搜索和推荐：

```python
# 获取文本嵌入
response = client.embeddings.create(
    model="text-embedding-ada-002",
    input="人工智能正在改变我们的生活和工作方式。"
)

embedding = response.data[0].embedding
print(f"嵌入向量维度: {len(embedding)}")
print(f"前5个数值: {embedding[:5]}")

# 计算两段文本的相似度
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

text1 = "人工智能是计算机科学的一个分支。"
text2 = "机器学习是人工智能的一个子领域。"

# 获取嵌入
response1 = client.embeddings.create(
    model="text-embedding-ada-002",
    input=text1
)
embedding1 = response1.data[0].embedding

response2 = client.embeddings.create(
    model="text-embedding-ada-002",
    input=text2
)
embedding2 = response2.data[0].embedding

# 计算余弦相似度
similarity = cosine_similarity([embedding1], [embedding2])[0][0]
print(f"文本相似度: {similarity}")
```

### 使用系统消息引导模型行为

系统消息是引导模型行为的有效方式：

```python
# 不同系统消息示例
system_messages = [
    # 角色定义
    "你是一位金融专家，具有丰富的投资咨询经验。",
    
    # 风格引导
    "请使用简短、直接的语言回答问题，避免冗长解释。",
    
    # 格式指导
    "请用Markdown格式组织回答，使用标题、列表和强调来提高可读性。",
    
    # 步骤引导
    "解决问题时，请先分析问题本质，然后提供可行的解决方案，最后总结关键点。",
    
    # 限制引导
    "请只提供与Python编程相关的建议，不要回答其他领域的问题。"
]

# 示例用法
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": system_messages[3]},
        {"role": "user", "content": "如何提高团队的工作效率？"}
    ]
)
print(response.choices[0].message.content)
```

## 主流大模型API比较

不同API服务之间存在一些差异：

| 服务提供商 | 优势 | 限制 | 价格参考 | 最适合场景 |
|---------|------|------|---------|-----------|
| OpenAI  | 性能强大，API成熟 | 国际付款，内容限制 | GPT-3.5: ~$0.002/1K tokens<br>GPT-4: ~$0.03/1K tokens | 通用AI应用开发 |
| Anthropic | 更安全可控，减少偏见 | API功能较少 | Claude: ~$0.008/1K tokens | 需要安全性的企业应用 |
| Google  | 与Google服务集成 | 某些地区可用性 | PaLM: ~$0.001/1K tokens | 需与Google生态系统集成 |
| Cohere | 专注于文本应用 | 模型规模小于GPT-4 | ~$0.0015/1K tokens | 文本处理和生成 |
| 百度/讯飞 | 中文处理优势 | 功能有限 | 按调用次数和模型计费 | 中文应用和国内部署 |

## API调用最佳实践

### 控制API成本

1. **批量请求**：将多个相似请求合并为一个
2. **缓存响应**：缓存常见问题的回答
3. **先使用较小模型**：先用GPT-3.5，必要时再用GPT-4
4. **优化提示词**：使提示词更简洁明确
5. **监控使用量**：设置预算和告警机制

```python
import redis

# 使用Redis缓存模型响应
redis_client = redis.Redis(host='localhost', port=6379, db=0)
cache_expiry = 3600  # 缓存过期时间（秒）

def get_cached_response(prompt):
    # 生成缓存键
    cache_key = f"llm_response:{hash(prompt)}"
    
    # 检查缓存
    cached_response = redis_client.get(cache_key)
    if cached_response:
        print("使用缓存的响应")
        return cached_response.decode('utf-8')
    
    # 如果没有缓存，调用API
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    result = response.choices[0].message.content
    
    # 缓存结果
    redis_client.setex(cache_key, cache_expiry, result)
    return result
```

### 安全性考虑

1. **API密钥管理**：使用环境变量，避免硬编码
2. **输入验证**：检查用户输入，防止注入攻击
3. **内容过滤**：过滤敏感信息和个人数据
4. **输出审核**：审核模型输出，防止有害内容
5. **访问控制**：限制API使用权限

```python
import os
import re

# 使用环境变量获取API密钥
api_key = os.environ.get("OPENAI_API_KEY")
if not api_key:
    raise ValueError("未设置API密钥环境变量")

# 敏感信息过滤
def filter_sensitive_info(text):
    # 过滤手机号
    text = re.sub(r'1[3-9]\d{9}', '[电话号码]', text)
    # 过滤邮箱
    text = re.sub(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', '[邮箱]', text)
    # 过滤身份证号
    text = re.sub(r'\d{17}[\dXx]', '[身份证号]', text)
    return text

# 使用过滤后的输入
user_input = filter_sensitive_info(raw_user_input)
```

### 增强可靠性

1. **重试机制**：处理临时错误和速率限制
2. **超时处理**：设置合理的超时时间
3. **并发控制**：管理并发请求数量
4. **日志记录**：记录请求和响应，便于调试
5. **监控告警**：监控API可用性和性能

```python
import logging
import time
from concurrent.futures import ThreadPoolExecutor

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("api_calls.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("openai_api")

# 并发请求控制
executor = ThreadPoolExecutor(max_workers=5)  # 限制最大并发数

def process_batch(prompts):
    results = []
    futures = []
    
    # 提交并发请求
    for prompt in prompts:
        futures.append(executor.submit(make_api_call, [{"role": "user", "content": prompt}]))
    
    # 获取结果
    for future in futures:
        try:
            result = future.result(timeout=30)  # 设置超时时间
            results.append(result)
        except Exception as e:
            logger.error(f"API调用失败: {e}")
            results.append("处理请求时发生错误")
    
    return results
```

## 实践任务：构建智能客服系统

:::{.task}
使用OpenAI API构建一个简单的智能客服系统，要求：

1. 能够回答关于产品信息、价格和退货政策的问题
2. 具有上下文记忆功能，能够理解多轮对话
3. 当无法回答问题时，能优雅地转人工客服
4. 记录对话历史，用于后续分析
5. 实现基本的错误处理和重试机制

**提示**：
- 使用系统消息定义客服角色和行为
- 维护会话历史记录
- 使用正则表达式或关键词匹配识别需要转人工的请求
- 实现日志记录功能
:::

## 其他大模型API示例

### 百度文心API

```python
import requests
import json

API_KEY = "your_api_key"
SECRET_KEY = "your_secret_key"

def get_access_token():
    url = "https://aip.baidubce.com/oauth/2.0/token"
    params = {
        "grant_type": "client_credentials",
        "client_id": API_KEY,
        "client_secret": SECRET_KEY
    }
    response = requests.post(url, params=params)
    return response.json().get("access_token")

def call_wenxin_api(prompt):
    url = "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions?access_token=" + get_access_token()
    
    payload = json.dumps({
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ]
    })
    headers = {
        'Content-Type': 'application/json'
    }
    
    response = requests.post(url, headers=headers, data=payload)
    return response.json()

# 使用示例
result = call_wenxin_api("介绍一下中国的人工智能发展现状")
print(result["result"])
```

### Anthropic Claude API

```python
from anthropic import Anthropic

# 初始化客户端
anthropic = Anthropic(api_key="your_api_key")

# 发送请求
response = anthropic.messages.create(
    model="claude-2",
    max_tokens=1000,
    messages=[
        {"role": "user", "content": "请帮我总结Transformer模型的关键创新点。"}
    ]
)

print(response.content)
```

## 总结

本章介绍了大模型API的基本用法和高级技巧，包括OpenAI API的详细调用方法、多轮对话管理、错误处理、函数调用等高级功能，以及API调用的最佳实践。通过合理使用这些API，开发者可以将AI能力无缝集成到各类应用中，创造更智能、更自然的用户体验。

在下一章中，我们将学习如何使用LangChain等工具构建更复杂的基于大模型的应用，实现更高级的功能如长文本处理、知识库问答和Agent构建。 