# 文本处理与自然语言处理

本章节将介绍Python中的文本处理技术以及利用Hugging Face进行高级自然语言处理的方法。随着大语言模型的发展，自然语言处理能力已经有了质的飞跃，掌握相关技能对商业智能分析至关重要。


## 1. 文本处理基础

### 1.1 Python字符串操作

Python内置了强大的字符串处理功能：

```python
# 基本字符串操作
text = "Python与AI驱动的现代商务智能"
print(len(text))  # 长度
print(text.upper())  # 大写
print(text.lower())  # 小写
print(text.replace("Python", "编程"))  # 替换
print(text.split("与"))  # 分割

# 字符串格式化
name = "Python"
version = 3.9
print(f"{name}的当前版本是{version}")  # f-string格式化
```

### 1.2 正则表达式

正则表达式是文本处理的强大工具：

```python
import re

text = "联系方式：电话：010-12345678，邮箱：example@domain.com"

# 提取电话号码
phone_pattern = r'\d{3}-\d{8}'
phones = re.findall(phone_pattern, text)
print("电话：", phones)

# 提取邮箱
email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
emails = re.findall(email_pattern, text)
print("邮箱：", emails)
```

### 1.3 基础文本预处理

```python
import pandas as pd
import numpy as np
import re

# 示例：清洗文本数据
def clean_text(text):
    if isinstance(text, str):
        # 转小写
        text = text.lower()
        # 移除特殊字符
        text = re.sub(r'[^\w\s]', '', text)
        # 移除数字
        text = re.sub(r'\d+', '', text)
        # 移除多余空格
        text = re.sub(r'\s+', ' ', text).strip()
        return text
    return ""

# 应用到数据框
df = pd.DataFrame({
    'text': ["这是一个例子！123", "Another example - with symbols.", np.nan]
})
df['cleaned_text'] = df['text'].apply(clean_text)
print(df)
```

## 2. 使用NLTK和spaCy进行文本分析

### 2.1 NLTK基础操作

```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

text = "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence."

# 分词
tokens = word_tokenize(text)
print("分词结果：", tokens[:5])

# 停用词过滤
stop_words = set(stopwords.words('english'))
filtered_tokens = [w for w in tokens if w.lower() not in stop_words]
print("过滤停用词后：", filtered_tokens[:5])

# 词形还原
lemmatizer = WordNetLemmatizer()
lemmatized = [lemmatizer.lemmatize(w) for w in filtered_tokens]
print("词形还原后：", lemmatized[:5])
```

### 2.2 使用spaCy进行中文处理

```python
import spacy

# 加载中文模型
nlp = spacy.load("zh_core_web_sm")

text = "华为公司是一家总部位于中国深圳的跨国科技公司。"
doc = nlp(text)

# 词性标注
for token in doc:
    print(f"单词: {token.text}, 词性: {token.pos_}, 命名实体: {token.ent_type_ if token.ent_type_ else '无'}")

# 命名实体识别
for ent in doc.ents:
    print(f"实体: {ent.text}, 类型: {ent.label_}")

# 依存句法分析
for token in doc:
    print(f"单词: {token.text}, 依存关系: {token.dep_}, 指向: {token.head.text}")
```

## 3. Hugging Face与现代NLP

[Hugging Face](https://huggingface.co/)是一个专注于自然语言处理的平台，提供了大量开源模型和工具，下面介绍其核心功能和高级应用。

### 3.1 Transformers库简介

```python
from transformers import pipeline

# 使用流水线API进行快速推理
classifier = pipeline("sentiment-analysis")
result = classifier("我非常喜欢这门课程！")
print(result)

# 命名实体识别
ner = pipeline("ner", aggregation_strategy="simple")
result = ner("Apple公司的CEO Tim Cook今天宣布了新产品")
print(result)

# 文本生成
generator = pipeline("text-generation")
result = generator("在商业智能中，数据分析可以", max_length=50)
print(result[0]['generated_text'])
```

### 3.2 使用预训练模型处理中文

```python
from transformers import BertTokenizer, BertModel
import torch

# 加载中文BERT模型
tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')
model = BertModel.from_pretrained('bert-base-chinese')

# 对文本进行编码
text = "大数据分析对企业决策有重要影响"
encoded_input = tokenizer(text, return_tensors='pt')

# 获取BERT输出
with torch.no_grad():
    output = model(**encoded_input)

# 提取句子表示（使用[CLS]token的输出）
sentence_embedding = output.last_hidden_state[:, 0, :]
print("句子嵌入维度:", sentence_embedding.shape)
```

### 3.3 微调预训练模型

```python
from transformers import BertForSequenceClassification, Trainer, TrainingArguments
from datasets import load_dataset
import numpy as np
from sklearn.metrics import accuracy_score

# 加载数据集
dataset = load_dataset("tnews")  # 中文新闻分类数据集

# 预处理函数
def preprocess_function(examples):
    return tokenizer(examples["text"], truncation=True, padding="max_length")

# 预处理数据
tokenized_dataset = dataset.map(preprocess_function, batched=True)

# 评估函数
def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return {"accuracy": accuracy_score(labels, predictions)}

# 设置训练参数
training_args = TrainingArguments(
    output_dir="./results",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
)

# 初始化模型
model = BertForSequenceClassification.from_pretrained("bert-base-chinese", num_labels=15)

# 初始化训练器
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    eval_dataset=tokenized_dataset["validation"],
    compute_metrics=compute_metrics,
)

# 训练模型
trainer.train()
```

### 3.4 高级应用：零样本和少样本学习

```python
from transformers import T5Tokenizer, T5ForConditionalGeneration

# 加载中文T5模型
tokenizer = T5Tokenizer.from_pretrained("uer/t5-base-chinese-cluecorpussmall")
model = T5ForConditionalGeneration.from_pretrained("uer/t5-base-chinese-cluecorpussmall")

# 零样本分类示例
def zero_shot_classify(text, labels):
    prompt = f"文本：{text}\n请将上述文本分类为以下类别之一：{', '.join(labels)}。类别："
    input_ids = tokenizer(prompt, return_tensors="pt").input_ids
    outputs = model.generate(input_ids, max_length=10)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# 测试
text = "京东将投入10亿元用于物流系统升级"
labels = ["科技", "经济", "体育", "娱乐"]
print(zero_shot_classify(text, labels))
```

### 3.5 结合VS Code/Cursor与AI插件使用Hugging Face

VS Code和Cursor都提供了强大的AI辅助功能，结合Hugging Face可以极大提升开发效率：

1. **代码补全**：AI插件可以帮助补全Hugging Face API调用代码
2. **错误修复**：快速识别和修复Hugging Face使用中的问题
3. **文档生成**：为复杂的NLP管道自动生成文档
4. **代码重构**：优化处理大规模文本数据的代码

示例工作流：

```python
# 以下代码可在VS Code/Cursor中编写，利用AI插件辅助完成

# 1. 安装必要的库
# !pip install transformers datasets torch

# 2. 导入库
from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer
import pandas as pd

# 3. 加载数据（AI插件会根据上下文提供相关代码建议）
df = pd.read_csv('customer_reviews.csv')

# 4. 使用Hugging Face进行情感分析
sentiment_analyzer = pipeline("sentiment-analysis", 
                             model="uer/roberta-base-finetuned-jd-binary-chinese")

# 5. AI插件会建议对大数据集进行批处理的代码模式
results = []
for batch in [df['review'].tolist()[i:i+32] for i in range(0, len(df), 32)]:
    batch_results = sentiment_analyzer(batch)
    results.extend(batch_results)

# 6. 将结果添加到数据框
df['sentiment'] = [r['label'] for r in results]
df['confidence'] = [r['score'] for r in results]

# 7. 可视化结果（AI插件可提供数据可视化代码）
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='sentiment')
plt.title('客户评论情感分布')
plt.show()
```

## 4. 商业智能中的文本挖掘应用

### 4.1 客户评论分析

```python
from transformers import pipeline
import pandas as pd
import matplotlib.pyplot as plt

# 加载客户评论数据
reviews = pd.DataFrame({
    'review': [
        "这个产品质量非常好，我很满意。",
        "送货速度太慢了，差评！",
        "性价比高，但是外观一般。",
        "客服态度很好，解决了我的问题。"
    ]
})

# 情感分析
sentiment_analyzer = pipeline("sentiment-analysis")
reviews['sentiment'] = [result['label'] for result in sentiment_analyzer(reviews['review'].tolist())]
reviews['score'] = [result['score'] for result in sentiment_analyzer(reviews['review'].tolist())]

# 方面提取（使用零样本分类）
classifier = pipeline("zero-shot-classification")
aspects = ["质量", "价格", "服务", "外观"]

for i, review in enumerate(reviews['review']):
    result = classifier(review, aspects)
    reviews.at[i, 'primary_aspect'] = result['labels'][0]
    
# 可视化
plt.figure(figsize=(10, 6))
reviews.groupby('primary_aspect').size().plot(kind='bar')
plt.title('客户评论主要关注点')
plt.ylabel('评论数量')
plt.show()
```

### 4.2 市场情报提取

```python
from transformers import pipeline
import pandas as pd

# 收集新闻文章
news_articles = [
    "小米公司今日发布新款手机，售价3999元起，主打长续航和影像功能。",
    "苹果公司宣布下一代iPhone将支持卫星通信功能，适用于紧急情况。",
    "华为发布新款折叠屏手机，价格较上一代下降15%，市场反响热烈。"
]

# 命名实体识别
ner = pipeline("ner", aggregation_strategy="simple")
entities = []

for article in news_articles:
    result = ner(article)
    for entity in result:
        entities.append({
            'text': entity['word'],
            'type': entity['entity_group'],
            'article': article[:30] + "..."
        })

# 转换为DataFrame
entities_df = pd.DataFrame(entities)
print(entities_df)

# 信息提取（使用问答模型）
qa_model = pipeline("question-answering")
questions = [
    "什么公司发布了新产品？",
    "新产品的价格是多少？",
    "产品有什么主要功能？"
]

for article in news_articles:
    print(f"\n文章: {article}")
    for question in questions:
        result = qa_model(question=question, context=article)
        print(f"问题: {question}")
        print(f"回答: {result['answer']} (置信度: {result['score']:.2f})")
```

### 4.3 文档智能搜索

```python
from transformers import AutoTokenizer, AutoModel
import torch
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# 加载模型
tokenizer = AutoTokenizer.from_pretrained("uer/sbert-base-chinese-nli")
model = AutoModel.from_pretrained("uer/sbert-base-chinese-nli")

# 示例文档集合
documents = [
    "人工智能技术正在改变零售业的客户体验。",
    "大数据分析帮助企业做出更明智的决策。",
    "云计算降低了企业的IT基础设施成本。",
    "深度学习在图像识别领域取得了突破性进展。",
    "区块链技术为供应链管理带来了透明度。"
]

# 计算文档嵌入
def get_embedding(text):
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    with torch.no_grad():
        outputs = model(**inputs)
    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()

document_embeddings = np.array([get_embedding(doc) for doc in documents])

# 搜索函数
def semantic_search(query, top_k=2):
    query_embedding = get_embedding(query)
    similarities = cosine_similarity([query_embedding], document_embeddings)[0]
    top_indices = similarities.argsort()[-top_k:][::-1]
    return [(documents[i], similarities[i]) for i in top_indices]
```

## 5. 课后实践与项目

### 5.1 使用VS Code/Cursor和AI辅助工具完成以下任务

1. **文本分类系统**：构建一个产品评论分类系统，区分正面、负面和中性评论
2. **关键信息提取**：从新闻文章中提取公司名称、产品、价格等关键信息
3. **文本摘要生成**：实现一个自动生成长文档摘要的系统
4. **情感分析仪表盘**：构建一个可视化仪表盘，实时分析社交媒体上的品牌情感

### 5.2 项目要求

- 充分利用VS Code/Cursor的AI辅助功能
- 使用Hugging Face提供的最新模型
- 注重代码质量和文档撰写
- 结合实际商业场景
- 考虑模型的计算效率和部署方案

### 5.3 提示与建议

- 开始时使用预训练模型直接应用
- 逐步尝试模型微调以提高效果
- 利用AI插件生成的代码模板，但确保理解其工作原理
- 关注处理中文文本的特殊要求
- 优先考虑模型在商业智能中的实际应用价值

## 参考资源

1. [Hugging Face官方文档](https://huggingface.co/docs)
2. [Transformers中文文档](https://huggingface.co/docs/transformers/zh/index)
3. [VS Code Python插件文档](https://code.visualstudio.com/docs/languages/python)
4. [Cursor AI编辑器官网](https://cursor.sh/) 