# 数据清洗与转换

在数据分析流程中，数据清洗是最耗时但也是最关键的步骤之一。原始数据通常包含缺失值、异常值、重复项等问题，需要通过数据清洗和转换使其成为可用于分析的格式。本章将介绍使用Python，特别是Pandas库进行数据清洗与转换的方法。

## 数据质量问题

在开始数据清洗前，我们需要了解常见的数据质量问题：

:::{.important}
1. **缺失值**：数据中的空值或缺失项
2. **异常值**：与大多数数据显著偏离的值
3. **重复数据**：完全相同或仅部分属性相同的重复记录
4. **格式不一致**：同一字段中的数据格式不统一
5. **数据类型不正确**：字段的数据类型与其实际含义不匹配
6. **单位不一致**：同一量纲的数据使用不同单位
7. **编码问题**：文本编码不一致导致的乱码
8. **结构性问题**：数据结构不符合分析需求
:::

## Pandas基础回顾

在深入数据清洗前，我们先简要回顾Pandas的基础操作：

```python
import pandas as pd
import numpy as np

# 创建DataFrame
df = pd.DataFrame({
    'A': [1, 2, np.nan, 4, 5],
    'B': [5, 6, 7, np.nan, 9],
    'C': ['a', 'b', 'c', 'd', np.nan]
})

# 基本信息查看
print(df.info())         # 数据类型和非空值计数
print(df.describe())     # 数值列的统计摘要
print(df.head())         # 查看前几行数据
print(df.shape)          # 数据集形状(行数、列数)
print(df.isnull().sum()) # 每列缺失值计数
```

## 数据清洗流程

一个典型的数据清洗流程包括以下步骤：

1. 数据导入与初步检查
2. 处理缺失值
3. 处理异常值和重复值
4. 数据类型转换与格式统一
5. 创建、修改和删除字段
6. 数据合并与重构

下面我们详细介绍每个步骤。

### 1. 数据导入与初步检查

```python
# 导入数据
df = pd.read_csv('data.csv')

# 初步检查
print(df.head())  # 查看前几行
print(df.info())  # 检查数据类型和缺失值
print(df.describe())  # 数值列统计摘要

# 检查缺失值
missing_values = df.isnull().sum()
print(missing_values[missing_values > 0])  # 只显示有缺失值的列

# 检查重复值
print(f"重复行数量: {df.duplicated().sum()}")
```

### 2. 处理缺失值

处理缺失值的策略取决于数据的性质和分析目的：

```python
# 1. 删除包含缺失值的行
df_drop_rows = df.dropna()

# 2. 删除特定缺失比例过高的列
threshold = len(df) * 0.5  # 设置阈值，例如50%
df_drop_cols = df.dropna(axis=1, thresh=threshold)

# 3. 使用固定值填充缺失值
df_fill_fixed = df.fillna(0)  # 用0填充所有缺失值
df_fill_dict = df.fillna({'A': 0, 'B': 1, 'C': 'unknown'})  # 不同列用不同值填充

# 4. 使用统计值填充缺失值
df_fill_mean = df.fillna(df.mean())  # 用均值填充数值列缺失值
df_fill_median = df.fillna(df.median())  # 用中位数填充
df_fill_mode = df.fillna(df.mode().iloc[0])  # 用众数填充

# 5. 使用前向或后向填充
df_ffill = df.fillna(method='ffill')  # 用前一个值填充(前向填充)
df_bfill = df.fillna(method='bfill')  # 用后一个值填充(后向填充)

# 6. 使用插值填充
df_interp = df.interpolate()  # 线性插值填充数值列
```

在选择缺失值处理策略时，需要考虑以下因素：
- 缺失值的比例和分布
- 数据的类型和性质
- 缺失的原因
- 分析的目的

:::{.tip}
对于时间序列数据，通常使用前向/后向填充或插值；对于分类数据，通常使用众数；对于数值特征，可以使用均值、中位数或基于相似记录的预测值。
:::

### 3. 处理异常值和重复值

#### 检测和处理异常值

```python
# 1. 使用描述性统计检测异常值
print(df.describe())

# 2. 使用箱线图可视化检测异常值
import matplotlib.pyplot as plt
df.boxplot(column=['A', 'B'])
plt.show()

# 3. 使用Z-score检测异常值
from scipy import stats
z_scores = stats.zscore(df[['A', 'B']])
abs_z_scores = abs(z_scores)
filtered_entries = (abs_z_scores < 3).all(axis=1)
df_no_outliers = df[filtered_entries]

# 4. 使用IQR(四分位距)检测异常值
Q1 = df['A'].quantile(0.25)
Q3 = df['A'].quantile(0.75)
IQR = Q3 - Q1
filter = (df['A'] >= Q1 - 1.5 * IQR) & (df['A'] <= Q3 + 1.5 * IQR)
df_no_outliers = df[filter]

# 5. 替换异常值
df['A'] = df['A'].clip(lower=df['A'].quantile(0.05), upper=df['A'].quantile(0.95))
```

#### 处理重复值

```python
# 检查重复行
print(df.duplicated().sum())

# 查看重复行
print(df[df.duplicated()])

# 删除完全重复的行
df_no_duplicates = df.drop_duplicates()

# 根据特定列删除重复项
df_no_duplicates = df.drop_duplicates(subset=['A', 'B'], keep='first')
```

### 4. 数据类型转换与格式统一

```python
# 检查数据类型
print(df.dtypes)

# 转换数据类型
df['A'] = df['A'].astype('float64')
df['B'] = df['B'].astype('int32')
df['Date'] = pd.to_datetime(df['Date'])  # 字符串转日期类型

# 处理分类变量
df['Category'] = df['Category'].astype('category')

# 字符串操作统一格式
df['Name'] = df['Name'].str.lower()  # 转小写
df['Name'] = df['Name'].str.strip()  # 去除空格
df['Phone'] = df['Phone'].str.replace('-', '')  # 删除特定字符
```

### 5. 创建、修改和删除字段

```python
# 创建新字段
df['C'] = df['A'] + df['B']
df['Year'] = df['Date'].dt.year  # 从日期提取年份
df['Month'] = df['Date'].dt.month  # 从日期提取月份

# 使用apply应用自定义函数
def categorize(value):
    if value < 0:
        return 'Negative'
    elif value == 0:
        return 'Zero'
    else:
        return 'Positive'

df['A_Category'] = df['A'].apply(categorize)

# 条件创建字段
df['Status'] = np.where(df['A'] > 0, 'Active', 'Inactive')

# 重命名字段
df = df.rename(columns={'A': 'Value_A', 'B': 'Value_B'})

# 删除字段
df = df.drop(columns=['unwanted_column'])
```

### 6. 数据合并与重构

```python
# 纵向合并(增加行)
df_combined = pd.concat([df1, df2], ignore_index=True)

# 横向合并(增加列)
df_merged = pd.merge(df1, df2, on='key_column', how='left')

# 数据透视
df_pivot = df.pivot(index='A', columns='B', values='C')

# 宽转长格式
df_long = pd.melt(df, id_vars=['ID'], value_vars=['A', 'B', 'C'],
                 var_name='Variable', value_name='Value')

# 长转宽格式
df_wide = df_long.pivot(index='ID', columns='Variable', values='Value')
```

## 实践案例：电子商务数据清洗

以下是一个电子商务数据集清洗的完整示例：

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

# 1. 数据导入
df = pd.read_csv('ecommerce_data.csv')

# 2. 初步检查
print("数据形状:", df.shape)
print("\n数据前5行:")
print(df.head())
print("\n数据类型和非空值计数:")
print(df.info())
print("\n数值列统计摘要:")
print(df.describe())

# 3. 处理缺失值
# 检查缺失值
missing_values = df.isnull().sum()
print("\n每列缺失值数量:")
print(missing_values[missing_values > 0])

# 处理缺失的客户ID - 删除这些行
df = df.dropna(subset=['customer_id'])

# 处理缺失的价格 - 用产品均价填充
df['price'] = df['price'].fillna(df.groupby('product_id')['price'].transform('mean'))

# 仍然缺失的价格用总体均价填充
df['price'] = df['price'].fillna(df['price'].mean())

# 4. 处理异常值
# 检查价格的箱线图
plt.figure(figsize=(10, 6))
df.boxplot(column=['price'])
plt.title('Price Distribution')
plt.savefig('price_boxplot.png')

# 使用IQR方法处理价格异常值
Q1 = df['price'].quantile(0.25)
Q3 = df['price'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# 替换异常值为上下界
df['price'] = df['price'].clip(lower=lower_bound, upper=upper_bound)

# 5. 处理重复值
print(f"\n重复行数量: {df.duplicated().sum()}")
df = df.drop_duplicates()

# 6. 数据类型转换
# 转换日期字段
df['order_date'] = pd.to_datetime(df['order_date'])

# 转换产品ID为类别型
df['product_id'] = df['product_id'].astype('category')
df['customer_id'] = df['customer_id'].astype('category')

# 7. 创建新字段
# 从日期提取年、月、日、星期
df['year'] = df['order_date'].dt.year
df['month'] = df['order_date'].dt.month
df['day'] = df['order_date'].dt.day
df['weekday'] = df['order_date'].dt.weekday

# 创建总金额字段
df['total_amount'] = df['price'] * df['quantity']

# 8. 数据聚合分析
# 按月份聚合销售额
monthly_sales = df.groupby('month')['total_amount'].sum().reset_index()
print("\n月度销售额:")
print(monthly_sales)

# 9. 保存清洗后的数据
df.to_csv('clean_ecommerce_data.csv', index=False)
print("\n数据清洗完成，已保存到clean_ecommerce_data.csv")
```

## 实践任务：房产数据清洗

:::{.task}
完成以下数据清洗任务：

假设你获得了一个房产数据集，包含以下字段：ID, 区域, 价格, 面积, 卧室数, 卫生间数, 建成年份, 房产类型, 更新日期。

原始数据存在以下问题：
1. 价格字段存在缺失值和异常值
2. 面积单位不一致，部分为平方米，部分为平方英尺
3. 建成年份有错误数据（如未来年份）
4. 更新日期格式混乱，有多种日期格式
5. 存在完全重复的记录

请编写代码完成以下清洗流程：
1. 导入数据并检查基本信息
2. 处理价格的缺失值和异常值
3. 统一面积单位（全部转为平方米）
4. 修正建成年份的错误
5. 标准化日期格式
6. 删除重复记录
7. 创建新字段：房龄（当前年份-建成年份）
8. 保存清洗后的数据

参考代码框架：

```python
import pandas as pd
import numpy as np
from datetime import datetime

# 导入数据
df = pd.read_csv('real_estate.csv')

# 1. 数据检查
print(df.info())
print(df.describe())
print(df.isnull().sum())

# 2. 处理价格
# 检测价格异常值
# ...
# 处理价格缺失值和异常值
# ...

# 3. 统一面积单位
# 假设数据集中有一列'area_unit'标记单位，或者需要从其他特征推断
# 1平方英尺 ≈ 0.092903平方米
# ...

# 4. 修正建成年份
current_year = datetime.now().year
# ...

# 5. 标准化日期格式
# ...

# 6. 删除重复记录
# ...

# 7. 创建房龄字段
# ...

# 8. 保存清洗后的数据
df.to_csv('clean_real_estate.csv', index=False)
```
:::

## 数据清洗的最佳实践

1. **保留原始数据**：永远不要直接修改原始数据文件，始终保留一份原始副本
2. **记录清洗步骤**：使用注释或Markdown记录每个清洗步骤，确保可复现
3. **分步骤清洗**：将数据清洗分为多个逻辑步骤，便于调试和维护
4. **检查结果**：每个清洗步骤后，检查结果确保符合预期
5. **处理异常情况**：使用try-except处理可能出现的异常
6. **关注领域知识**：数据清洗不仅是技术问题，还需要领域知识的指导
7. **自动化流程**：对于定期获取的数据，构建自动化的清洗流程
8. **可视化验证**：使用可视化方法验证清洗效果

## 总结

数据清洗是数据分析过程中最基础但也是最重要的步骤，它直接影响分析结果的质量。本章介绍了使用Pandas进行数据清洗的方法，包括处理缺失值、异常值、重复值，转换数据类型，统一格式以及数据重构等。掌握这些技术可以帮助你准备高质量的数据集，为后续的数据分析和建模奠定基础。

在下一章中，我们将学习文本数据处理的方法，这是处理非结构化数据的重要技能。 